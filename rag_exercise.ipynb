{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "from langchain.chains.openai_functions import create_structured_output_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import os\n",
    "import time\n",
    "from langchain.llms import Ollama \n",
    "from langchain.document_loaders import WebBaseLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import GPT4AllEmbeddings \n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url='bolt://localhost:7687',\n",
    "    username='neo4j',\n",
    "    password='password',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = Ollama(base_url='http://localhost:11434', model='llama2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_1 = WebBaseLoader('https://www.thoughtworks.com/en-de/insights/articles/data-mesh-in-practice-technology-and-the-architecture')\n",
    "system_2 = WebBaseLoader('https://www.thoughtworks.com/en-de/insights/articles/data-mesh-in-practice-organizational-operating-model')\n",
    "system_3 = WebBaseLoader('https://www.thoughtworks.com/en-de/insights/articles/data-mesh-in-practice-product-thinking-and-development')\n",
    "loader = WebBaseLoader('https://www.thoughtworks.com/en-in/insights/blog/data-strategy/dev-experience-data-mesh-product')\n",
    "loader_1 = WebBaseLoader('https://www.thoughtworks.com/en-in/insights/blog/data-strategy/dev-experience-data-mesh-platform')\n",
    "raw_documents = loader_1.load() + loader.load() + system_1.load() + system_2.load() + system_3.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import JSON\n",
    "from trulens_eval import TruChain, Feedback,Tru\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(\"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.  \n",
    "\n",
    "RULES:                                               \n",
    "DO NOT INCLUDE THE INFORMATION IN YOUR ANSWER.\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(raw_documents)\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=GPT4AllEmbeddings())\n",
    "qachain_full_stuff = RetrievalQA.from_chain_type(llm=ollama, chain_type=\"stuff\", retriever=vectorstore.as_retriever(),chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In relevance_with_cot_reasons, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In relevance_with_cot_reasons, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import LiteLLM\n",
    "import litellm\n",
    "litellm.set_verbose=False\n",
    "ollama_provider = LiteLLM(model_engine=\"ollama/llama2\", api_base='http://localhost:11434')\n",
    "relevance = Feedback(ollama_provider.relevance_with_cot_reasons).on_input_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9, {'reason': 'Criteria: Relevance to the given prompt \\n'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama_provider.relevance_with_cot_reasons(\"what are tools used in?\", \"Snowflake,Talend,DBT,Collibra,Monte Carlo,Dataops.live,SOLE,OAMClient libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(qachain_full_stuff,\n",
    "    app_id='normal_rag',\n",
    "    feedbacks=[relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you for providing the context. To answer your question, a data product differs from a data asset in that a data product is created to serve a specific user-driven goal as identified in the Lean Value Tree, while a data asset can be any entity composed of data, such as databases or application output files.\\n\\nA data product is subject to clearly defined Service Level Objectives (SLOs) and is owned by a single domain or stakeholder, maintained by a single data product team. Additionally, a data product is designed to meet the consumption requirements of specific consumers, who may access or consume it through various channels.\\n\\nIn contrast, a data asset does not have these specific goals, SLOs, or ownership structures, and its purpose may not be directly tied to meeting the needs of a particular consumer group.\\n\\nI hope this helps clarify the difference between a data product and a data asset. If you have any further questions, please let me know!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = qachain_full_stuff.run(\"what is data product\")\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>relevance_with_cot_reasons</th>\n",
       "      <th>relevance_with_cot_reasons_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal_rag</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruChain\", \"modul...</td>\n",
       "      <td>RetrievalQA(langchain.chains.retrieval_qa.base)</td>\n",
       "      <td>record_hash_7479619b6f5a210c472ccd9ad83ff40b</td>\n",
       "      <td>\"what is data product\"</td>\n",
       "      <td>\"Thank you for providing the context. To answe...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_7479619b6f5a210c472...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-05T11:46:15.080033\", \"...</td>\n",
       "      <td>2024-01-05T11:46:27.773222</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'args': {'prompt': 'what is data product', '...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       app_id                                           app_json  \\\n",
       "0  normal_rag  {\"tru_class_info\": {\"name\": \"TruChain\", \"modul...   \n",
       "\n",
       "                                              type  \\\n",
       "0  RetrievalQA(langchain.chains.retrieval_qa.base)   \n",
       "\n",
       "                                      record_id                   input  \\\n",
       "0  record_hash_7479619b6f5a210c472ccd9ad83ff40b  \"what is data product\"   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"Thank you for providing the context. To answe...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_7479619b6f5a210c472...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-01-05T11:46:15.080033\", \"...   \n",
       "\n",
       "                           ts  relevance_with_cot_reasons  \\\n",
       "0  2024-01-05T11:46:27.773222                         0.9   \n",
       "\n",
       "                    relevance_with_cot_reasons_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'prompt': 'what is data product', '...       12             0   \n",
       "\n",
       "   total_cost  \n",
       "0         0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_records_and_feedback(app_ids=[])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j RAG (Parent Retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TokenTextSplitter\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WikipediaLoader\n\u001b[0;32m----> 6\u001b[0m parent_splitter \u001b[38;5;241m=\u001b[39m \u001b[43mTokenTextSplitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m child_splitter \u001b[38;5;241m=\u001b[39m TokenTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m)\n\u001b[1;32m      9\u001b[0m parent_documents \u001b[38;5;241m=\u001b[39m parent_splitter\u001b[38;5;241m.\u001b[39msplit_documents(raw_documents)\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/langchain/text_splitter.py:722\u001b[0m, in \u001b[0;36mTokenTextSplitter.__init__\u001b[0;34m(self, encoding_name, model_name, allowed_special, disallowed_special, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m     enc \u001b[38;5;241m=\u001b[39m tiktoken\u001b[38;5;241m.\u001b[39mencoding_for_model(model_name)\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 722\u001b[0m     enc \u001b[38;5;241m=\u001b[39m \u001b[43mtiktoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer \u001b[38;5;241m=\u001b[39m enc\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allowed_special \u001b[38;5;241m=\u001b[39m allowed_special\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/tiktoken/registry.py:73\u001b[0m, in \u001b[0;36mget_encoding\u001b[0;34m(encoding_name)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown encoding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoding_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Plugins found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_available_plugin_modules()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     72\u001b[0m constructor \u001b[38;5;241m=\u001b[39m ENCODING_CONSTRUCTORS[encoding_name]\n\u001b[0;32m---> 73\u001b[0m enc \u001b[38;5;241m=\u001b[39m Encoding(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mconstructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     74\u001b[0m ENCODINGS[encoding_name] \u001b[38;5;241m=\u001b[39m enc\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m enc\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/tiktoken_ext/openai_public.py:11\u001b[0m, in \u001b[0;36mgpt2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgpt2\u001b[39m():\n\u001b[0;32m---> 11\u001b[0m     mergeable_ranks \u001b[38;5;241m=\u001b[39m \u001b[43mdata_gym_to_mergeable_bpe_ranks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_bpe_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://openaipublic.blob.core.windows.net/gpt-2/encodings/main/vocab.bpe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_json_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://openaipublic.blob.core.windows.net/gpt-2/encodings/main/encoder.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplicit_n_vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50257\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecial_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: {ENDOFTEXT: \u001b[38;5;241m50256\u001b[39m},\n\u001b[1;32m     21\u001b[0m     }\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/tiktoken/load.py:99\u001b[0m, in \u001b[0;36mdata_gym_to_mergeable_bpe_ranks\u001b[0;34m(vocab_bpe_file, encoder_json_file)\u001b[0m\n\u001b[1;32m     94\u001b[0m     n \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# check that the encoder file matches the merges file\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# this sanity check is important since tiktoken assumes that ranks are ordered the same\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# as merge priority\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m encoder_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mread_file_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_json_file\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    100\u001b[0m encoder_json_loaded \u001b[38;5;241m=\u001b[39m {decode_data_gym(k): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m encoder_json\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# drop these two special tokens if present, since they're not mergeable bpe tokens\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/tiktoken/load.py:50\u001b[0m, in \u001b[0;36mread_file_cached\u001b[0;34m(blobpath)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cache_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 50\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblobpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(cache_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/tiktoken/load.py:24\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(blobpath)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# avoiding blobfile for public files helps avoid auth issues, like MFA prompts\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblobpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m resp\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/requests/sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 747\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/http/client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniforge3/envs/rag_qa/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ingestion of data in the neo4j graph\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "\n",
    "\n",
    "parent_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=24)\n",
    "child_splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=24)\n",
    "\n",
    "parent_documents = parent_splitter.split_documents(raw_documents)\n",
    "\n",
    "for d in parent_documents:\n",
    "    child_documents = child_splitter.split_documents([d])\n",
    "    parent_text = d.page_content\n",
    "    child_texts = [c.page_content for c in child_documents]\n",
    "\n",
    "    # Create parent node and child nodes with relationships\n",
    "    graph.query(\n",
    "        \"\"\"\n",
    "        UNWIND $children AS child\n",
    "        CREATE (p:Parent {text: $parent})\n",
    "        CREATE (c:Child {text: child})\n",
    "        CREATE (c)-[:HAS_PARENT]->(p)\n",
    "        \"\"\",\n",
    "        {\"parent\": parent_text, \"children\": child_texts}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "\n",
    "retrieval_query = \"\"\"\n",
    "MATCH (node)-[:HAS_PARENT]->(parent)\n",
    "RETURN parent.text AS text, score, {} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "from langchain.embeddings import (\n",
    "    OllamaEmbeddings,\n",
    "    SentenceTransformerEmbeddings,\n",
    "    BedrockEmbeddings,\n",
    ")\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    GPT4AllEmbeddings(),\n",
    "    url='bolt://localhost:7687',\n",
    "    username='neo4j',\n",
    "    password='password',\n",
    "    index_name=\"new_index_name\",\n",
    "    node_label=\"Child\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\",\n",
    "    retrieval_query=retrieval_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qachain = RetrievalQA.from_chain_type(llm=ollama, chain_type=\"stuff\", retriever=vector_index.as_retriever(),chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(qachain,\n",
    "    app_id='neo4j_parental_rag',\n",
    "    feedbacks=[relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A data product is a structured set of data that provides value to a particular stakeholder or use case. It can be thought of as a \"productized\" data asset, meaning that it has been organized and packaged in a way that makes it easy for consumers to access, consume, and utilize.\\n\\nData products typically have the following characteristics:\\n\\n1. Defined scope and purpose: The data product has a clear definition of what it is intended to do and who it is intended to serve.\\n2. Structured data: The data product is organized in a way that makes it easy for consumers to find and use the data they need. This may involve breaking down large datasets into smaller, more manageable chunks or creating new data entities to represent specific concepts or relationships.\\n3. Consistent and reliable: The data product is designed to be consistent and reliable, so that consumers can rely on it to provide accurate and up-to-date information.\\n4. Valuable: The data product provides value to the consumer, whether that value is in the form of insights, recommendations, or some other form of assistance.\\n5. Easy to use: The data product is designed to be easy for consumers to use, with clear documentation and intuitive interfaces.\\n6. Flexible: The data product can adapt to changing requirements and new use cases as needed.\\n7. Scalable: The data product can handle large volumes of data and scale to meet the needs of a growing user base.\\n8. Secure: The data product is designed to protect sensitive information and maintain privacy and security throughout its lifecycle.\\n\\nBy defining clear SLIs (Service Level Indicators) and SLOs (Service Level Objectives), data product teams can measure and ensure that their data products are meeting the required level of service quality, reliability, and performance. This helps to ensure that the data product is delivering value to its consumers and stakeholders, and that it is able to adapt and evolve over time to meet changing requirements and use cases.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = qachain.run(\"what is data product\")\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>relevance_with_cot_reasons</th>\n",
       "      <th>relevance_with_cot_reasons_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal_rag</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruChain\", \"modul...</td>\n",
       "      <td>RetrievalQA(langchain.chains.retrieval_qa.base)</td>\n",
       "      <td>record_hash_7479619b6f5a210c472ccd9ad83ff40b</td>\n",
       "      <td>\"what is data product\"</td>\n",
       "      <td>\"Thank you for providing the context. To answe...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_7479619b6f5a210c472...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-05T11:46:15.080033\", \"...</td>\n",
       "      <td>2024-01-05T11:46:27.773222</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'args': {'prompt': 'what is data product', '...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neo4j_parental_rag</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruChain\", \"modul...</td>\n",
       "      <td>RetrievalQA(langchain.chains.retrieval_qa.base)</td>\n",
       "      <td>record_hash_9744ee3913a215d5b877d6ffd22f89c8</td>\n",
       "      <td>\"what is data product\"</td>\n",
       "      <td>\"A data product is a structured set of data th...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_9744ee3913a215d5b87...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-01-05T11:48:04.136092\", \"...</td>\n",
       "      <td>2024-01-05T11:48:43.352390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               app_id                                           app_json  \\\n",
       "0          normal_rag  {\"tru_class_info\": {\"name\": \"TruChain\", \"modul...   \n",
       "1  neo4j_parental_rag  {\"tru_class_info\": {\"name\": \"TruChain\", \"modul...   \n",
       "\n",
       "                                              type  \\\n",
       "0  RetrievalQA(langchain.chains.retrieval_qa.base)   \n",
       "1  RetrievalQA(langchain.chains.retrieval_qa.base)   \n",
       "\n",
       "                                      record_id                   input  \\\n",
       "0  record_hash_7479619b6f5a210c472ccd9ad83ff40b  \"what is data product\"   \n",
       "1  record_hash_9744ee3913a215d5b877d6ffd22f89c8  \"what is data product\"   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"Thank you for providing the context. To answe...    -   \n",
       "1  \"A data product is a structured set of data th...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_7479619b6f5a210c472...   \n",
       "1  {\"record_id\": \"record_hash_9744ee3913a215d5b87...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "1  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-01-05T11:46:15.080033\", \"...   \n",
       "1  {\"start_time\": \"2024-01-05T11:48:04.136092\", \"...   \n",
       "\n",
       "                           ts  relevance_with_cot_reasons  \\\n",
       "0  2024-01-05T11:46:27.773222                         0.9   \n",
       "1  2024-01-05T11:48:43.352390                         NaN   \n",
       "\n",
       "                    relevance_with_cot_reasons_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'prompt': 'what is data product', '...       12             0   \n",
       "1                                                NaN       12             0   \n",
       "\n",
       "   total_cost  \n",
       "0         0.0  \n",
       "1         0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_records_and_feedback(app_ids=[])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa49667407e44d479509905a8f8eaade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.1.6:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.start_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.stop_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(qachain,\n",
    "    app_id='neo4j_parental_rag',\n",
    "    feedbacks=[relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don\\'t have personal experiences or knowledge about the specific context you provided, but I can try to help you understand it better.\\n\\nBased on the information provided in the article, \"Data Mesh in practice: Technology and architecture (Part IV)\" by Ammara Gafoor, Ian Murdoch, and Kiran Prakash, the authors discuss their learnings from implementing Data Mesh at Roche. They highlight the importance of technology and architecture in supporting data mesh practices.\\n\\nIn the article, the authors mention that Data Mesh is built on top of a robust technology stack, which includes Snowflake for storage, Compute for computation, and Monte Carlo for monitoring. They also note that the platform provides an isolation layer between the application and the underlying infrastructure, which allows for more agile development and faster time-to-market for data products.\\n\\nThe authors also discuss the importance of having a well-thought-out architecture to support data mesh practices. They mention that Data Mesh provides a pre-configured architecture that includes pre-built components and templates, which can help reduce the time and effort required to build and deploy data products. Additionally, they highlight the importance of having a flexible and scalable architecture to support the diverse range of data products that are developed using Data Mesh.\\n\\nOverall, the article emphasizes the critical role that technology and architecture play in supporting data mesh practices, and how these practices can help organizations develop and deploy data products more efficiently and effectively.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = qachain.run(\"what is life\")\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(qachain_full_stuff,\n",
    "    app_id='normal_rag',\n",
    "    feedbacks=[relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'langchain.chains.retrieval_qa.base.RetrievalQA'> at 0x2905f4280 is calling an instrumented method <function Chain.__call__ at 0x11f6bc5e0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x2c40d1950) using this function.\n",
      "A new object of type <class 'langchain.chains.retrieval_qa.base.RetrievalQA'> at 0x2905f4280 is calling an instrumented method <function BaseRetrievalQA._call at 0x12a60c2c0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x2c40d1950) using this function.\n",
      "A new object of type <class 'langchain_core.vectorstores.VectorStoreRetriever'> at 0x17f128cd0 is calling an instrumented method <function BaseRetriever.get_relevant_documents at 0x11f697880>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app.retriever based on other object (0x2c40d1630) using this function.\n",
      "A new object of type <class 'langchain_core.vectorstores.VectorStoreRetriever'> at 0x17f128cd0 is calling an instrumented method <function VectorStoreRetriever._get_relevant_documents at 0x12a32c4a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app.retriever based on other object (0x2c40d1630) using this function.\n",
      "A new object of type <class 'langchain.chains.combine_documents.stuff.StuffDocumentsChain'> at 0x17f128eb0 is calling an instrumented method <function Chain.__call__ at 0x11f6bc5e0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x2c40d1950) using this function.\n",
      "A new object of type <class 'langchain.chains.combine_documents.stuff.StuffDocumentsChain'> at 0x17f128eb0 is calling an instrumented method <function BaseCombineDocumentsChain._call at 0x11f79f920>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app.combine_documents_chain based on other object (0x2c40d0c80) using this function.\n",
      "A new object of type <class 'langchain.chains.llm.LLMChain'> at 0x2905f41e0 is calling an instrumented method <function Chain.__call__ at 0x11f6bc5e0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x2c40d1950) using this function.\n",
      "A new object of type <class 'langchain.chains.llm.LLMChain'> at 0x2905f41e0 is calling an instrumented method <function LLMChain._call at 0x11f6ecd60>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app.combine_documents_chain.llm_chain based on other object (0x2c40d15e0) using this function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Thank you for providing the context. Based on the information provided, I don\\'t know the answer to your question \"what is life.\" The context does not provide any information that would help me answer this question. Please let me know if there is anything else I can help you with.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = qachain_full_stuff.run(\"what is life\")\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path:   Network URL: http://192.168.1.6:8501\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.start_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo4j_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
